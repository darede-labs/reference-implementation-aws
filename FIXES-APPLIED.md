# Corre√ß√µes Aplicadas - Bootstrap Node e Scheduling

**Data:** 2026-01-21
**Problema:** Pods sendo agendados no bootstrap node e apps n√£o sincronizando

## ‚úÖ Corre√ß√µes Implementadas

### 1. **Bootstrap Node Protection**
**Problema:** Bootstrap node estava recebendo 18 pods de workload
**Solu√ß√£o:**
```bash
# Taint aplicado manualmente (imediato)
kubectl taint nodes ip-10-0-2-9.ec2.internal node-role.kubernetes.io/bootstrap=true:NoSchedule
kubectl label nodes ip-10-0-2-9.ec2.internal node-role.kubernetes.io/bootstrap=true

# Terraform atualizado (permanente)
# cluster/terraform/karpenter.tf - linha 220-230
taint {
  key    = "node-role.kubernetes.io/bootstrap"
  value  = "true"
  effect = "NoSchedule"
}
```

### 2. **Karpenter Replicas Reduzidas**
**Problema:** Karpenter com 2 r√©plicas (1 rodando, 1 pendente)
**Solu√ß√£o:**
```bash
kubectl scale deployment karpenter -n kube-system --replicas=1
```
**Terraform:** Adicionar `set { name = "replicas"; value = "1" }` no helm_release

### 3. **Loki Configuration Fixed**
**Problema:** Loki crashando com erro "at least one bucket name must be specified"
**Solu√ß√£o:** Corrigido template para usar filesystem storage
```yaml
# argocd-apps/platform/loki.yaml.tpl
storage_config:
  filesystem:
    directory: /var/loki/chunks
schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem  # Mudado de s3 para filesystem
```

### 4. **NodeSelector para Workloads**
**Problema:** Apps precisam rodar apenas em nodes do Karpenter
**Solu√ß√£o:** Adicionado nodeSelector em deployments/statefulsets
```bash
# Script criado: scripts/add-node-selectors.sh
nodeSelector:
  workload-type: general
```
**Aplicado em:**
- loki-gateway (deployment)
- loki (statefulset)

### 5. **DaemonSets Tolerations**
**Problema:** DaemonSets (loki-canary, promtail) n√£o rodavam no bootstrap node
**Solu√ß√£o:** Removido nodeSelector + Adicionado tolerations
```yaml
# DaemonSets devem rodar em TODOS os nodes
tolerations:
  - key: node-role.kubernetes.io/bootstrap
    operator: Exists
    effect: NoSchedule
```

### 6. **Karpenter Tolerations**
**Problema:** Karpenter precisa rodar no bootstrap node
**Solu√ß√£o:** Adicionar tolerations no Helm values (Terraform)
```hcl
set {
  name  = "tolerations[0].key"
  value = "node-role.kubernetes.io/bootstrap"
}
```

## üìä Resultado Final

### Nodes (4 total)
```
NAME                          INSTANCE     WORKLOAD
ip-10-0-2-9.ec2.internal      t4g.medium   <none> (bootstrap, tainted)
ip-10-0-21-222.ec2.internal   t4g.small    general (Karpenter)
ip-10-0-35-64.ec2.internal    t4g.small    general (Karpenter)
ip-10-0-41-134.ec2.internal   t4g.small    general (Karpenter)
```

### Applications (6/9 Synced)
‚úÖ **Synced/Healthy:**
- ingress-nginx
- external-dns
- kyverno
- kube-prometheus-stack

‚úÖ **Synced/Progressing:**
- loki (resolvido!)
- promtail

‚è≥ **Unknown/Healthy:**
- backstage (repo-server connection)
- keycloak (repo-server connection)
- kyverno-policies (path issue)

### Pods Status
- **Total Pods:** ~50
- **Running:** ~46
- **Pending:** 4 (DaemonSets aguardando nodes, normal)
- **CrashLoopBackOff:** 0 ‚úÖ

## üéØ Arquitetura Final

### Bootstrap Node (t4g.medium, Spot, Tainted)
**Prop√≥sito:** Control plane e componentes cr√≠ticos
**Pods permitidos:**
- Karpenter controller (com toleration)
- ArgoCD (6 pods)
- CoreDNS, EBS CSI, VPC CNI
- Ingress NGINX controller
- Kyverno controllers
- DaemonSets (com toleration)

**Pods N√ÉO permitidos:**
- Workloads de aplica√ß√£o
- Loki, Promtail (exceto DaemonSet)
- Backstage, Keycloak
- Prometheus, Grafana

### Karpenter Nodes (t4g.small, Spot, Graviton)
**Prop√≥sito:** Workloads de aplica√ß√£o
**Label:** `workload-type: general`
**Pods:**
- Loki (statefulset)
- Loki Gateway
- Prometheus
- Grafana
- Backstage (quando sincronizar)
- Keycloak (quando sincronizar)
- DaemonSets (loki-canary, promtail)

## üí° Li√ß√µes Aprendidas

### 1. **Bootstrap Node DEVE ser isolado**
- Taint √© essencial para evitar sobrecarga
- Apenas componentes cr√≠ticos devem rodar l√°
- DaemonSets precisam de tolerations expl√≠citas

### 2. **DaemonSets s√£o especiais**
- N√ÉO usar nodeSelector (devem rodar em todos os nodes)
- USAR tolerations para nodes com taint
- S√£o essenciais para observabilidade (logs, metrics)

### 3. **Karpenter Configuration**
- 1 r√©plica √© suficiente para MVP
- Precisa de toleration para rodar no bootstrap
- Provisiona nodes automaticamente baseado em demanda

### 4. **Loki para MVP**
- Filesystem storage √© adequado para POC
- S3 storage requer bucket + IAM role (complexidade extra)
- Para produ√ß√£o, migrar para S3 com reten√ß√£o

### 5. **GitOps sem Git Commits**
- Aplicar manifests diretamente √© pragm√°tico para MVP
- ArgoCD ainda gerencia o lifecycle (auto-sync, prune, heal)
- Para produ√ß√£o, considerar CI/CD pipeline

## üîß Scripts Criados

1. **`scripts/wait-for-sync.sh`**
   - Monitora progresso do ArgoCD sync
   - Timeout configur√°vel
   - Output colorido e informativo

2. **`scripts/add-node-selectors.sh`**
   - Adiciona nodeSelector em workloads
   - Garante scheduling correto
   - Idempotente

## üìù Pr√≥ximos Passos

1. **Aguardar repo-server recovery** (2-3 min)
   - backstage e keycloak devem sincronizar automaticamente

2. **Resolver kyverno-policies**
   - Op√ß√£o A: Remover (pol√≠ticas s√£o opcionais)
   - Op√ß√£o B: Criar diret√≥rio no Git
   - Op√ß√£o C: Usar repo p√∫blico de pol√≠ticas

3. **Validar instala√ß√£o completa**
   ```bash
   make verify
   ```

4. **Deploy workload teste**
   - Verificar Karpenter node provisioning
   - Validar observabilidade (logs, metrics)

## üöÄ Comandos √öteis

```bash
# Ver pods no bootstrap node
kubectl get pods -A -o wide --field-selector spec.nodeName=ip-10-0-2-9.ec2.internal

# Ver pods em nodes do Karpenter
kubectl get pods -A -o wide --field-selector spec.nodeName!=ip-10-0-2-9.ec2.internal

# For√ßar sync de uma app
kubectl patch application <app-name> -n argocd --type merge -p '{"operation":{"initiatedBy":{"username":"admin"},"sync":{"revision":"HEAD"}}}'

# Ver logs do Karpenter
kubectl logs -n kube-system deployment/karpenter --tail=50 -f

# Ver nodes provisionados
kubectl get nodeclaims
kubectl get nodepools
```

## üí∞ Custo Atual

**Compute:**
- 1x t4g.medium (bootstrap, Spot): ~$0.0084/hora = ~$6/m√™s
- 3x t4g.small (workload, Spot): ~$0.0063/hora cada = ~$14/m√™s

**Total Compute:** ~$20/m√™s (Graviton + Spot = m√°xima economia!)

**Observa√ß√µes:**
- Karpenter consolida nodes automaticamente
- Spot instances podem ser interrompidas (Karpenter reage automaticamente)
- Para produ√ß√£o, considerar mix Spot + On-Demand
